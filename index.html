<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="EARL">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="Expanding the Action Space of LLMs to Reason Beyond Language
">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="Zhongqi Yue, Weishi Wang, Yundaichuan Zhan, Juncheng Li, Daniel Dahlmeier, Fredrik D. Johansson">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="Chalmers & SAP & ZJU">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="EARL">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="Expanding the Action Space of LLMs to Reason Beyond Language">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://expa-rl.github.io/">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="Zhongqi Yue, Weishi Wang, Yundaichuan Zhan, Juncheng Li, Daniel Dahlmeier, Fredrik D. Johansson">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">

  <title>EARL</title>
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/EARL.png">
  <link rel="apple-touch-icon" href="static/images/EARL.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <style>
    .text-highlight {
      font-size: 1.15em;       /* 放大字体 */
      font-weight: 700;       /* 加粗 */
      color: #1e3a8a; /* 深蓝色 (Tailwind Blue-900 类似) */
    }
    .small-image {
      width: auto;
      height: 40px;
      vertical-align: middle; /* to align the image with the text */
      margin-top: 10px;
      margin-right: 12px; /* to give some space between the image and the text */
    }

    .small-image-logo {
        width: auto;
        height: 50px;
        margin-top: -7px;
        vertical-align: middle; /* to align the image with the text */
        margin-right: 5px; /* to give some space between the image and the text */
    }
    .small-image-55 {
        width: auto;
        height: 55px;
        vertical-align: middle; /* to align the image with the text */
        margin-top: 10px;
        margin-right: 12px; /* to give some space between the image and the text */
    }

    .small-image-50 {
        width: auto;
        height: 50px;
        vertical-align: middle; /* to align the image with the text */
        margin-top: 10px;
        margin-right: 12px; /* to give some space between the image and the text */
    }

    .small-image-45 {
        width: auto;
        height: 45px;
        vertical-align: middle; /* to align the image with the text */
        margin-top: 10px;
        margin-right: 12px; /* to give some space between the image and the text */
    }

    .small-image-60 {
        width: auto;
        height: 60px;
        vertical-align: middle; /* to align the image with the text */
        margin-top: 10px;
        margin-right: 12px; /* to give some space between the image and the text */
    }

    .small-image-35 {
        width: auto;
        height: 35px;
        vertical-align: middle; /* to align the image with the text */
        margin-top: 10px;
        margin-right: 12px; /* to give some space between the image and the text */
    }

    .small-image-30 {
        width: auto;
        height: 30px;
        vertical-align: middle; /* to align the image with the text */
        margin-top: 10px;
        margin-right: 12px; /* to give some space between the image and the text */
    }

    .small-image-20 {
        width: auto;
        height: 20px;
        vertical-align: middle; /* to align the image with the text */
        margin-top: 10px;
        margin-right: 12px; /* to give some space between the image and the text */
    }
    .small-image-25 {
        width: auto;
        height: 25px;
        vertical-align: middle; /* to align the image with the text */
        margin-top: 10px;
        margin-right: 12px; /* to give some space between the image and the text */
    }
    .table .num { text-align: right; white-space: nowrap; }
    .ref-link {
      color: inherit;                  /* 保持文字颜色一致 */
      text-decoration: underline;      /* 添加下划线 */
      text-underline-offset: 3px;      /* 调整下划线位置 */
      transition: all 0.2s ease-in-out;
    }
    .ref-link:hover {
      text-decoration-thickness: 2px;  /* 鼠标悬停时略微加粗下划线 */
      color: var(--primary-color);     /* 悬停时可轻微变主题色（可选） */
    }
  </style>

  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>
  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <template id="hidden-block">
  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <!-- TODO: Replace with your lab's related works -->
        <a href="https://arxiv.org/abs/PAPER_ID_1" class="work-item" target="_blank">
          <div class="work-info">
            <!-- TODO: Replace with actual paper title -->
            <h5>Paper Title 1</h5>
            <!-- TODO: Replace with brief description -->
            <p>Brief description of the work and its main contribution.</p>
            <!-- TODO: Replace with venue and year -->
            <span class="work-venue">Conference/Journal 2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <!-- TODO: Add more related works or remove extra items -->
        <a href="https://arxiv.org/abs/PAPER_ID_2" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 2</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_3" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 3</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>
  </template>







  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">EARL: Expanding the Action Space of LLMs to Reason Beyond Language</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://yue-zhongqi.github.io/" target="_blank">Zhongqi Yue</a><sup>1*</sup>,
                <a href="https://scholar.google.com/citations?user=P8TGNcoAAAAJ&hl=en" target="_blank">Weishi Wang</a><sup>2*</sup>,
                <a href="https://scholar.google.com/citations?user=rP5Imh4AAAAJ&hl=en" target="_blank">Yundaichuan Zhan</a><sup>3</sup>,
                <a href="https://scholar.google.com/citations?user=lm9s-QgAAAAJ&hl=en" target="_blank">Juncheng Li</a><sup>3</sup>,
                <a href="https://scholar.google.com/citations?user=IrwwO8cAAAAJ&hl=en" target="_blank">Daniel Dahlmeier</a><sup>2</sup>,
                <a href="https://scholar.google.com/citations?user=ml-AyBQAAAAJ&hl=en" target="_blank">Fredrik D. Johansson</a><sup>1</sup>
              </span>
            </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1 </sup><img src="static/images/Chalmers.svg" class="small-image-60">  <img src="static/images/Chamlers_Logo.png" class="small-image-30"></span>
                <span class="author-block"><sup>2 </sup><img src="static/images/SAP_Logo.png" class="small-image-55"></span>
                <span class="author-block"><sup>3 </sup><img src="static/images/ZJU_Logo.png" class="small-image-60"></span>
                <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution. zhongqi@chalmers.se, weishi.wang@sap.com</small></span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="https://github.com/yue-zhongqi/earl" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2510.07581.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
              </div>
            </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="rows">
            <div class="rows is-centered ">
                <p style="font-size: 120%; margin-bottom:1rem; line-height:1.6;">
                  <strong>TL;DR:</strong> We propose a new paradigm for post-training LLMs with external environments to incentivize reasoning and agentic behavior, showing promising results.
                </p>
                <p style="font-size: 120%; margin-bottom:1rem; line-height:1.6;">
                  Currently, interactions with external environments must be expressed through text in predefined formats, parsed, and routed to external interfaces. This overloads the model’s language with both reasoning and control duties, and requires a hand-crafted parser, external to the LLM. To address this, we decouple environment interactions from language by internalizing them in an Expanded Action space (<strong>ExpA</strong>), beyond the vocabulary. We illustrate how ExpA differs from traditional paradigm later. ExpA leads to promising results in 3 key areas.
                </p>
            </div>
        </div>
    </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3"><span class="dvima">1. Multi-turn Contingent Planning</span></h2>
      <p style="font-size: 120%; margin-bottom:1rem; line-height:1.6;">
        Many challenging reasoning tasks require not only multi-turn interactions with external environments but also <strong class="text-highlight">adaptive decision-making</strong> based on intermediate feedback. In our Countdown task (<a href="#figure1" class="ref-link">Figure 1</a>), agents must use an external calculator to reach a target number. Each problem admits up to 7,680 unique combinations, demanding efficient reasoning and dynamic strategy adjustment (e.g., shifting tactics when far from the target). Agents trained with ExpA Reinforcement Learning (<strong>EARL</strong>) significantly outperform strong vocabulary-constrained baselines (<a href="#figure1" class="ref-link">Figure 1</a>). Qualitative analysis (<a href="#table1" class="ref-link">Table 1</a>) further shows that the EARL agent respond more sensitively to intermediate observations, a key trait of effective planning.
      </p>
      
    <div class="item" id="figure1">
      <img src="static/images/countdown.png" loading="lazy"/>
      <p>
        <strong>Figure 1.</strong> Exact Match (%) comparison on the Countdown task. We fine-tune <strong>Qwen2.5-3B</strong> and <strong>Qwen2.5-7B</strong> on a multi-task benchmark that includes Countdown as a sub-task, and evaluate them on a held-out Countdown test set. Full benchmark results are provided in the paper.
      </p>
    </div>

<div class="table-container">
      <table class="table is-striped is-hoverable is-fullwidth is-narrow">
        
        <thead>
          <tr>
            <th>Phrase</th>
            <th class="has-text-right">EARL</th>
            <th class="has-text-right">Prompt+CPO</th>
            <th class="has-text-right">Prompt+GRPO</th>
            <th class="has-text-right">SFT+GRPO</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>not close</td>
            <td class="num">9,961</td>
            <td class="num">99</td>
            <td class="num">0</td>
            <td class="num">18</td>
          </tr>
          <tr>
            <td>is close</td>
            <td class="num">805</td>
            <td class="num">2,930</td>
            <td class="num">0</td>
            <td class="num">855</td>
          </tr>
          <tr>
            <td>close to</td>
            <td class="num">3,019</td>
            <td class="num">1,138</td>
            <td class="num">0</td>
            <td class="num">2,253</td>
          </tr>
          <tr>
            <td>still close</td>
            <td class="num">9</td>
            <td class="num">193</td>
            <td class="num">0</td>
            <td class="num">0</td>
          </tr>
          <tr>
            <td>different approach</td>
            <td class="num">7,586</td>
            <td class="num">92</td>
            <td class="num">1,650</td>
            <td class="num">15</td>
          </tr>
          <tr>
            <td>another approach</td>
            <td class="num">0</td>
            <td class="num">1,769</td>
            <td class="num">0</td>
            <td class="num">219</td>
          </tr>
          <tr>
            <td>different combination</td>
            <td class="num">8,851</td>
            <td class="num">39</td>
            <td class="num">2,040</td>
            <td class="num">377</td>
          </tr>
          <tr>
            <td>another combination</td>
            <td class="num">1,784</td>
            <td class="num">46</td>
            <td class="num">0</td>
            <td class="num">58</td>
          </tr>
          <tr>
            <td>negate</td>
            <td class="num">682</td>
            <td class="num">4</td>
            <td class="num">0</td>
            <td class="num">121</td>
          </tr>
          <tr>
            <td>far from</td>
            <td class="num">8,264</td>
            <td class="num">141</td>
            <td class="num">0</td>
            <td class="num">10</td>
          </tr>
        </tbody>
        <tfoot>
          <tr>
            <th>Total</th>
            <th class="num">40,961</th>
            <th class="num">6,451</th>
            <th class="num">3,690</th>
            <th class="num">3,926</th>
          </tr>
        </tfoot>
        <caption class="has-text-weight-semibold">
          <strong>Table 1.</strong> Number of occurrences of planning-related keywords in testing.
        </caption>
      </table>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3"><span class="dvima">2. Partially Observed Environment</span></h2>
      <p style="font-size: 120%; margin-bottom:1rem; line-height:1.6;">
        In agentic settings, LLMs can extend their reasoning into external environments by mapping language instructions into operations such as API calls or robotic control, allowing them to solve tasks in the digital or physical worlds. Such scenarios are typically partially observed, where the agent must interact with the environments to access their hidden states.
      </p>
      <p style="font-size: 120%; margin-bottom:1rem; line-height:1.6;">
        In this work, we train agents to order a set of hidden numbers using compare and swap environments, e.g., “compare A, B” reveals their relation, while “swap A, B” updates the hidden state. This task is challenging, as the agent must plan contingently from comparison outcomes, reason precisely over first-order relations, and manipulate hidden states through interactions rather than text output, which makes this a realistic testbed for interactive decision-making situations such as embodied AI.
      </p>
      <p style="font-size: 120%; margin-bottom:1rem; line-height:1.6;">
        Interestingly, agents with ExpA achieves perfect Sort-4 accuracy <strong class="text-highlight">with just 70 training steps</strong>, while self-discovering an efficient algorithm competitive with classical designs (<a href="#figure2" class="ref-link">Figure 2</a>).
      </p>
      
    <figure class="image" id="figure2">
      <video class="is-fullwidth" autoplay muted loop playsinline controls>
        <source src="static/videos/SORT.mp4" type="video/mp4">
      </video>
    </figure>
    <p>
      <strong>Figure 2.</strong> An example for reasoning with expanded actions.
    </p>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3"><span class="dvima">3. Readiness for Zero-RL</span></h2>
      <p style="font-size: 120%; margin-bottom:1rem; line-height:1.6;">
        To promote effective exploration of the expanded action space and new environments, we introduce ExpA Reinforcement Learning (<strong>EARL</strong>) with counterfactual policy optimization, which fully supports RL on base models, i.e., without requiring supervised tool-call data or adherence to predefined language patterns.
      </p>
    <h2 class="title is-4"><span class="dvima">Approach</span></h2>
    <p style="font-size: 120%; margin-bottom:1rem; line-height:1.6;">
      We propose a fundamental shift from the language-only paradigm for interacting with environments (<a href="#figure3" class="ref-link">Figure 3</a>). Our aim is threefold: 
    </p>  
    <ul style="font-size: 120%;margin-left:1rem; line-height:1.6; list-style-type: disc;">
        <li> Decouple environment interactions from language reasoning</li>
        <li> Enable end-to-end training by removing reliance on external parsers and keeping interactions under the model’s control.</li>
        <li> Fully support RL on base models, i.e., Zero-RL, without requiring supervised tool-call data or adherence to predefined language patterns.</li>
    </ul>
    <p style="font-size: 120%; margin-bottom:1rem; line-height:1.6;">
      We propose to expand the LLM’s action space for interactions (<a href="#figure4" class="ref-link">Figure 4</a>), and derive a training strategy to explore these interactions while supporting Zero-RL (<a href="#figure5" class="ref-link">Figure 5</a>).
    </p>
  </div>
  <div class="container is-max-desktop">
    <div class="columns is-vcentered is-variable is-6">
      <!-- left: video -->
      <div class="column is-6">
        <div class="column has-text-centered">
          <figure class="image" id="figure3">
            <video class="is-fullwidth" autoplay muted loop playsinline controls>
              <source src="static/videos/base_mdp.mp4" type="video/mp4">
            </video>
          </figure>
          <p>
            <strong>Figure 3.</strong> A simple example for reasoning with vocabulary-based interactions.
          </p>
        </div>
        
      </div>
      <!-- right: text -->
      <div class="column is-6">
        <h2 class="title is-4"><span class="dvima">Interactions by Vocabulary</span></h2>
          <p>
            In current works, LLMs can be viewed as agents acting in decision processes with an action space restricted to vocabulary. Interactions with external environments are mediated through a parser, which translates predefined text patterns (e.g., tool tags or structured JSON) into environment-specific actions, routed to the corresponding environment. The environment executes the actions and returns a plain-text observation, which is appended to the model's context.
          </p>
        </div>
      </div>
    </div>
  </div>
  <div class="container is-max-desktop">
    <div class="columns is-vcentered is-variable is-6">
      <div class="column is-6">
        <div class="column has-text-centered">
          <figure class="image" id="figure4">
            <video class="is-fullwidth" autoplay muted loop playsinline controls>
              <source src="static/videos/earl_mdp.mp4" type="video/mp4">
            </video>
          </figure>
          <p>
            <strong>Figure 4.</strong> An example for reasoning with expanded actions.
          </p>
        </div>
      </div>

      <div class="column is-6">
        <h2 class="title is-4"><span class="dvima">Interactions by Expanded Actions</span></h2>
          <p>
            We decouple environment interactions from language by internalizing them in an Expanded Action space (<strong>ExpA</strong>), beyond the vocabulary. The model starts reasoning in the default language environment, but may trigger routing actions and switch to an external environment at any time. From there, the model can only invoke environment-specific actions, receive feedback from the environment, and potentially route back to language as a result. This enable end-to-end training by removing reliance on external parsers and keeping interactions under the model’s control.
          </p>
        </div>
      </div>
    </div>
  </div>
  <div class="container is-max-desktop">
    <div class="columns is-vcentered is-variable is-6">
      <div class="column is-6">
        <div class="column has-text-centered">
          <figure class="image"  id="figure5">
            <video class="is-fullwidth" autoplay muted loop playsinline controls>
              <source src="static/videos/counterfactual.mp4" type="video/mp4">
            </video>
          </figure>
          <p>
            <strong>Figure 5.</strong> An example of counterfactual policy optimization, which involves both factual and counterfactual rollouts.
          </p>
        </div>
      </div>

      <div class="column is-6">
        <h2 class="title is-4"><span class="dvima">EARL with Counterfactual Policy Optimization</span></h2>
          <p>
            To promote effective exploration of the expanded action space and new environments, we employ ExpA with RL (<strong>ExpA</strong>). During training, for each (factual) rollout, we construct a counterfactual rollout by forcing a routing action at a plausible intermediate step, identified as a position where the model assigns high probability to the routingdescription token. The advantage is then computed as the difference between the counterfactual and original rewards, thereby encouraging exploration of rarely visited but essential environments.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- TODO: Replace with your teaser video -->
      <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
        <!-- TODO: Add your video file path here -->
        <source src="static/videos/banner_video.mp4" type="video/mp4">
      </video>
      <!-- TODO: Replace with your video description -->
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin ullamcorper tellus sed ante aliquam tempus. Etiam porttitor urna feugiat nibh elementum, et tempor dolor mattis. Donec accumsan enim augue, a vulputate nisi sodales sit amet. Proin bibendum ex eget mauris cursus euismod nec et nibh. Maecenas ac gravida ante, nec cursus dui. Vivamus purus nibh, placerat ac purus eget, sagittis vestibulum metus. Sed vestibulum bibendum lectus gravida commodo. Pellentesque auctor leo vitae sagittis suscipit.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- TODO: Replace with your research result images -->
        <img src="static/images/carousel1.jpg" alt="First research result visualization" loading="lazy"/>
        <!-- TODO: Replace with description of this result -->
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel2.jpg" alt="Second research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel3.jpg" alt="Third research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/carousel4.jpg" alt="Fourth research result visualization" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/carousel1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/carousel2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/carousel3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->

<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <div class="bibtex-header">
      <h2 class="title">BibTeX</h2>
      <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
        <i class="fas fa-copy"></i>
        <span class="copy-text">Copy</span>
      </button>
    </div>
    <pre id="bibtex-code">
      <code>
        @misc{2510.07581,
        Author = {Zhongqi Yue and Weishi Wang and Yundaichuan Zhan and Juncheng Li and Daniel Dahlmeier and Fredrik D. Johansson},
        Title = {Expanding the Action Space of LLMs to Reason Beyond Language},
        Year = {2025},
        Eprint = {arXiv:2510.07581},
        }
      </code>
    </pre>
  </div>
</section>
<!--End BibTex citation -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
